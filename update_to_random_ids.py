#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å°†äº§å“IDä»BOOK001æ ¼å¼æ”¹ä¸º8ä½éšæœºæ•°
æ›´æ–°æ‰€æœ‰ç›¸å…³æ–‡ä»¶å’Œæ˜ å°„
"""

import json
import random
import shutil
from pathlib import Path

def generate_8digit_id():
    """ç”Ÿæˆ8ä½éšæœºæ•°ID"""
    return f"{random.randint(10000000, 99999999)}"

def ensure_unique_ids(existing_ids, count):
    """ç¡®ä¿ç”Ÿæˆçš„IDæ˜¯å”¯ä¸€çš„"""
    new_ids = set()
    while len(new_ids) < count:
        new_id = generate_8digit_id()
        if new_id not in existing_ids and new_id not in new_ids:
            new_ids.add(new_id)
    return list(new_ids)

def backup_files():
    """å¤‡ä»½åŸå§‹æ–‡ä»¶"""
    files_to_backup = [
        "Ai_model/products.json",
        "Ai_model/ai_to_db_id_mapping.json", 
        "Ai_model/db_to_ai_id_mapping.json",
        "Ai_model/index_to_id.json"
    ]
    
    print("ğŸ“¦ å¤‡ä»½åŸå§‹æ–‡ä»¶...")
    for file_path in files_to_backup:
        if Path(file_path).exists():
            backup_path = f"{file_path}.backup"
            shutil.copy2(file_path, backup_path)
            print(f"âœ“ å¤‡ä»½: {file_path} -> {backup_path}")

def update_products_json(old_to_new_mapping):
    """æ›´æ–°products.jsonæ–‡ä»¶"""
    print("ğŸ“ æ›´æ–° products.json...")
    
    with open("Ai_model/products.json", "r", encoding="utf-8") as f:
        products = json.load(f)
    
    # æ›´æ–°äº§å“ID
    for product in products:
        old_id = product["product_id"]
        if old_id in old_to_new_mapping:
            product["product_id"] = old_to_new_mapping[old_id]
            print(f"   {old_id} -> {product['product_id']} ({product['product_name']})")
    
    # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
    with open("Ai_model/products.json", "w", encoding="utf-8") as f:
        json.dump(products, f, ensure_ascii=False, indent=4)
    
    print(f"âœ“ å·²æ›´æ–° {len(products)} ä¸ªäº§å“çš„ID")

def update_mapping_files(old_to_new_mapping):
    """æ›´æ–°IDæ˜ å°„æ–‡ä»¶"""
    print("ğŸ”„ æ›´æ–°IDæ˜ å°„æ–‡ä»¶...")
    
    # 1. æ›´æ–° ai_to_db_id_mapping.json
    with open("Ai_model/ai_to_db_id_mapping.json", "r", encoding="utf-8") as f:
        ai_to_db = json.load(f)
    
    new_ai_to_db = {}
    for old_ai_id, db_id in ai_to_db.items():
        if old_ai_id in old_to_new_mapping:
            new_ai_id = old_to_new_mapping[old_ai_id]
            new_ai_to_db[new_ai_id] = db_id
        else:
            new_ai_to_db[old_ai_id] = db_id
    
    with open("Ai_model/ai_to_db_id_mapping.json", "w", encoding="utf-8") as f:
        json.dump(new_ai_to_db, f, ensure_ascii=False, indent=2)
    
    # 2. æ›´æ–° db_to_ai_id_mapping.json
    with open("Ai_model/db_to_ai_id_mapping.json", "r", encoding="utf-8") as f:
        db_to_ai = json.load(f)
    
    new_db_to_ai = {}
    for db_id, old_ai_id in db_to_ai.items():
        if old_ai_id in old_to_new_mapping:
            new_ai_id = old_to_new_mapping[old_ai_id]
            new_db_to_ai[db_id] = new_ai_id
        else:
            new_db_to_ai[db_id] = old_ai_id
    
    with open("Ai_model/db_to_ai_id_mapping.json", "w", encoding="utf-8") as f:
        json.dump(new_db_to_ai, f, ensure_ascii=False, indent=2)
    
    # 3. æ›´æ–° index_to_id.json
    with open("Ai_model/index_to_id.json", "r", encoding="utf-8") as f:
        index_to_id = json.load(f)
    
    new_index_to_id = []
    for old_id in index_to_id:
        if old_id in old_to_new_mapping:
            new_index_to_id.append(old_to_new_mapping[old_id])
        else:
            new_index_to_id.append(old_id)
    
    with open("Ai_model/index_to_id.json", "w", encoding="utf-8") as f:
        json.dump(new_index_to_id, f, ensure_ascii=False, indent=2)
    
    print("âœ“ å·²æ›´æ–°æ‰€æœ‰æ˜ å°„æ–‡ä»¶")

def update_api_server_mappings(old_to_new_mapping):
    """æ›´æ–°APIæœåŠ¡å™¨ä¸­çš„ç¡¬ç¼–ç æ˜ å°„"""
    print("ğŸ¤– æ›´æ–°APIæœåŠ¡å™¨ä¸­çš„äº§å“æ˜ å°„...")
    
    api_server_file = "Ai_model/api_server.py"
    
    # è¯»å–æ–‡ä»¶å†…å®¹
    with open(api_server_file, "r", encoding="utf-8") as f:
        content = f.read()
    
    # æ›¿æ¢æ˜ å°„ä¸­çš„ID
    for old_id, new_id in old_to_new_mapping.items():
        # æ›¿æ¢å­—å…¸é”®
        content = content.replace(f"'{old_id}':", f"'{new_id}':")
        # æ›¿æ¢åˆ—è¡¨ä¸­çš„å¼•ç”¨
        content = content.replace(f"'{old_id}'", f"'{new_id}'")
    
    # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
    with open(api_server_file, "w", encoding="utf-8") as f:
        f.write(content)
    
    print("âœ“ å·²æ›´æ–°APIæœåŠ¡å™¨æ˜ å°„")

def display_mapping_summary(old_to_new_mapping):
    """æ˜¾ç¤ºæ˜ å°„æ€»ç»“"""
    print("\nğŸ“Š IDæ˜ å°„æ€»ç»“:")
    print("=" * 60)
    print(f"{'æ—§ID':<15} -> {'æ–°ID':<15} ç±»åˆ«")
    print("=" * 60)
    
    # æŒ‰ç±»åˆ«åˆ†ç»„æ˜¾ç¤º
    categories = {}
    for old_id, new_id in old_to_new_mapping.items():
        if old_id.startswith("BOOK"):
            category = "ä¹¦ç±"
        elif old_id.startswith("ELEC"):
            category = "ç”µå­äº§å“"
        elif old_id.startswith("SPORTS"):
            category = "è¿åŠ¨æˆ·å¤–"
        elif old_id.startswith("OFFICE"):
            category = "åŠå…¬ç”¨å“"
        else:
            category = "å…¶ä»–"
        
        if category not in categories:
            categories[category] = []
        categories[category].append((old_id, new_id))
    
    for category, mappings in categories.items():
        print(f"\n{category}:")
        for old_id, new_id in mappings:
            print(f"  {old_id:<13} -> {new_id:<13}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("   äº§å“IDæ ¼å¼è½¬æ¢ï¼šå­—ç¬¦ä¸² -> 8ä½éšæœºæ•°")
    print("=" * 60)
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    required_files = [
        "Ai_model/products.json",
        "Ai_model/ai_to_db_id_mapping.json",
        "Ai_model/db_to_ai_id_mapping.json",
        "Ai_model/index_to_id.json",
        "Ai_model/api_server.py"
    ]
    
    missing_files = [f for f in required_files if not Path(f).exists()]
    if missing_files:
        print("âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶:")
        for file in missing_files:
            print(f"   - {file}")
        return 1
    
    # 1. å¤‡ä»½æ–‡ä»¶
    backup_files()
    
    # 2. è¯»å–ç°æœ‰äº§å“
    print("\nğŸ“‹ è¯»å–ç°æœ‰äº§å“...")
    with open("Ai_model/products.json", "r", encoding="utf-8") as f:
        products = json.load(f)
    
    # æå–æ‰€æœ‰æ—§ID
    old_ids = [product["product_id"] for product in products]
    print(f"âœ“ æ‰¾åˆ° {len(old_ids)} ä¸ªäº§å“")
    
    # 3. ç”Ÿæˆæ–°çš„8ä½éšæœºæ•°ID
    print("ğŸ² ç”Ÿæˆ8ä½éšæœºæ•°ID...")
    new_ids = ensure_unique_ids(set(), len(old_ids))
    
    # åˆ›å»ºæ˜ å°„å…³ç³»
    old_to_new_mapping = dict(zip(old_ids, new_ids))
    
    # 4. æ˜¾ç¤ºæ˜ å°„é¢„è§ˆ
    display_mapping_summary(old_to_new_mapping)
    
    # 5. ç¡®è®¤æ›´æ–°
    print(f"\nâš ï¸  å³å°†æ›´æ–° {len(old_ids)} ä¸ªäº§å“ID")
    print("è¿™å°†å½±å“ä»¥ä¸‹æ–‡ä»¶:")
    for file in required_files:
        print(f"   - {file}")
    
    response = input("\næ˜¯å¦ç»§ç»­? (y/N): ").strip().lower()
    if response != 'y':
        print("âŒ æ“ä½œå·²å–æ¶ˆ")
        return 0
    
    try:
        # 6. æ‰§è¡Œæ›´æ–°
        print("\nğŸš€ å¼€å§‹æ›´æ–°...")
        update_products_json(old_to_new_mapping)
        update_mapping_files(old_to_new_mapping)
        update_api_server_mappings(old_to_new_mapping)
        
        print("\nğŸ‰ æ›´æ–°å®Œæˆ!")
        print("=" * 60)
        print("ğŸ“‹ æ›´æ–°æ€»ç»“:")
        print(f"   - å·²æ›´æ–° {len(old_ids)} ä¸ªäº§å“IDä¸º8ä½éšæœºæ•°")
        print(f"   - å·²æ›´æ–°æ‰€æœ‰æ˜ å°„æ–‡ä»¶")
        print(f"   - åŸå§‹æ–‡ä»¶å·²å¤‡ä»½ (*.backup)")
        print("\nğŸ’¡ ä¸‹æ¬¡å¯åŠ¨ç³»ç»Ÿæ—¶å°†ä½¿ç”¨æ–°çš„IDæ ¼å¼")
        print("   è¯·é‡æ–°å¯åŠ¨AIæœåŠ¡å™¨ä»¥åŠ è½½æ–°é…ç½®")
        
        return 0
        
    except Exception as e:
        print(f"âŒ æ›´æ–°è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print("ğŸ’¡ æ‚¨å¯ä»¥ä½¿ç”¨å¤‡ä»½æ–‡ä»¶æ¢å¤:")
        for file in required_files:
            if Path(f"{file}.backup").exists():
                print(f"   cp {file}.backup {file}")
        return 1

if __name__ == "__main__":
    import sys
    sys.exit(main()) 